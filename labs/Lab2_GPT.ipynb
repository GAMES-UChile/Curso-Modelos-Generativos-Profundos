{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "3ec1cec624ef406c8f6a8d3cb7b93d46",
    "deepnote_cell_type": "markdown",
    "id": "e4Pr6pv5ie50"
   },
   "source": [
    "**MDS7203 Modelos Generativos Profundos, Primavera 2023**\n",
    "\n",
    "# Laboratorio 2: Modelo de lenguaje auto-regresivo\n",
    "\n",
    "**Profesor**: Felipe Tobar, **Auxiliares**: Crist贸bal Alc谩zar, Camilo Carvajal Reyes, **Ayudante**: Joaqu铆n Barcel贸.\n",
    "\n",
    "**Fecha de entrega**: viernes 29 de septiembre 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "38cd31c023b047f080018f94f24927e8",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "**Nombre: COLOCAR AQU SU NOMBRE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "279c16d9f94a4b5dbe45f9f4f6ff6f07",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "**Instrucciones**: El presente notebook contiene enunciado e instrucciones para la realizaci贸n del laboratorio. Usted deber谩 completar los c贸digos (en este archivo o en una copia del mismo) donde se le pida hacerlo. Usted deber谩 entregar el notebook con sus respuestas, cumpliendo lo siguiente:\n",
    "\n",
    "- Los comentarios en c贸digo deben ser concisos pero claros. No se evaluar谩n sub-preguntas donde solo exista c贸digo sin comentarios pertinentes.\n",
    "- El c贸digo debe ser ordenado y ejectuable. No se evaluar谩n notebooks o scripts que generen errores en su ejecuci贸n. Se aconseja resetear la kernel y corroborar la correcta execuci贸n de todas las celdas antes de ejecutar el entrenamiento de su modelo.\n",
    "- Si bien se aconseja el uso de internet y otras herramientas para asistir su trabajo, asi como discusiones con el ED y estudiantes, el c贸digo que entregue debe ser de su autor铆a.\n",
    "\n",
    "El objetivo del laboratorio ser谩 implementar, desde casi cero, un modelo de lenguaje estilo GPT, i.e., basado en el uso de un bloque \"decoder\" de la arquitectura Transformer (como se muestra en la imagen a continuaci贸n). Este tipo de modelos es un ejemplo de modelo auto-regresivo y que ha tenido gran relevancia en el 煤ltimo tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.stack.imgur.com/bWnx0.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='https://i.stack.imgur.com/bWnx0.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunos links 煤tiles:\n",
    "\n",
    "* [Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)\n",
    "* [GPT2, original blog post](https://openai.com/research/better-language-models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "40d3aa47f3204ca888f874beb273d9f5",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Resumen de preguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "14369c673f3049a19e647a78a00686d4",
    "deepnote_cell_type": "text-cell-todo",
    "formattedRanges": []
   },
   "source": [
    "- [ ] a) (0,5 ptos.) Definici贸n de diccionarios para vocabulario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c3ae5920aed6440ea4c012068c08bb8b",
    "checked": false,
    "deepnote_cell_type": "text-cell-todo",
    "formattedRanges": []
   },
   "source": [
    "- [ ] b) (bonus) Utilizaci贸n de embeddings previo a la normalizaci贸n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d259ba9b76b74b2e8eb0132b06f7f31c",
    "checked": false,
    "deepnote_cell_type": "text-cell-todo",
    "formattedRanges": []
   },
   "source": [
    "- [ ] c) (bonus) Escalamiento por $1/\\sqrt{d_k}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "14547d4ff1564ceca8f1133b2bf3831f",
    "checked": false,
    "deepnote_cell_type": "text-cell-todo",
    "formattedRanges": []
   },
   "source": [
    "- [ ] d) (1.5 ptos.) Creaci贸n de clase `Head`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "806e04b64a5f4e8c9c46b8addb61da30",
    "checked": false,
    "deepnote_cell_type": "text-cell-todo",
    "formattedRanges": []
   },
   "source": [
    "- [ ] e) (0.75 pto.) Implementaci贸n de clase `FeedForward`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "af2c2194e9e94407b2ed8d38ac7dd9c5",
    "checked": false,
    "deepnote_cell_type": "text-cell-todo",
    "formattedRanges": []
   },
   "source": [
    "- [ ] f) (0.5 ptos.) Relaci贸n entre hiper-par谩metros n_head y head_size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9cec4a573e824ff2a535781db9773328",
    "checked": false,
    "deepnote_cell_type": "text-cell-todo",
    "formattedRanges": []
   },
   "source": [
    "- [ ] g) (0.75 ptos.) Forward pass en `DecoderBlock`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "33851255223c4c569a4ef98add7b0b4f",
    "checked": false,
    "deepnote_cell_type": "text-cell-todo",
    "formattedRanges": []
   },
   "source": [
    "- [ ] h) (1 pto.) Implementaci贸n clase `GPTLM`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "273f32755bf446cba8132463ead5c3ac",
    "checked": false,
    "deepnote_cell_type": "text-cell-todo",
    "formattedRanges": []
   },
   "source": [
    "- [ ] i) (1 pto.) Training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] j) (bonus) Comparar modelo con Baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "3381cfa7678849408eeaf9aedb7fb2d1",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5134,
    "execution_start": 1693917871424,
    "id": "xIPkmAHJmC9s",
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caracter铆sticas de la GPU, si es que est谩 disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "2bd1045c4e41414b88df0bae08b56b58",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 474,
    "execution_start": 1693859116039,
    "id": "CGoaBP7mygL4",
    "outputId": "921a9201-f250-4b10-a82a-280ac6ed6a03",
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a607d5c593c64504a2c445b78a01b637",
    "deepnote_cell_type": "markdown",
    "id": "O54vJC-DjbMe"
   },
   "source": [
    "## 1. Corpus \n",
    "\n",
    "Escoja uno de los dos datasets:\n",
    "- shakespeare.txt: concatenaci贸n de obras de shakespeare, ~ 1 millon de caracteres\n",
    "- cabromagico.txt: concatenaci贸n de los libros de Harry Potter, ~ 6 millones de caracteres\n",
    "\n",
    "Escoja en base a sus gustos y capacidades de c贸mputo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si usan collab, descargar dataset desde repo GAMES descomentando una de las siguientes lineas:\n",
    "# !wget https://raw.githubusercontent.com/GAMES-UChile/Curso-Modelos-Generativos-Profundos/main/labs/data/shakespeare.txt\n",
    "# !wget https://raw.githubusercontent.com/GAMES-UChile/Curso-Modelos-Generativos-Profundos/main/labs/data/cabromagico.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "23f881bed52248f8bfd4204bbdf4f3d1",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 19,
    "execution_start": 1693864731107,
    "id": "oC8C6LkJi21K",
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "with open('shakespeare.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "# with open('cabromagico.txt', 'r', encoding='utf-8') as file:\n",
    "#     text = file.read()\n",
    "\n",
    "print(f\"Tama帽o del corpus: {len(text):,} caracteres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "10a13a6c0fd849b584a6ab3a4f5991e6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 21,
    "execution_start": 1693859154739,
    "id": "Z-IuIqKHj0zL",
    "outputId": "fa8f8d5c-d2cb-463f-f0aa-37ddf0eddc79",
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "063a10ca987f4b479fb3b53b92f2ad52",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "> a) (0.5 ptos.) Dada una lista de ordenada de caracteres, defina:\n",
    "> - stoi: un diccionario caracter -> 铆ndice\n",
    "> - itos: un diccionario 铆ndice -> caracter\n",
    "> Con lo anterior, defina dos funciones encode y decode que tomen un string y una lista de 铆ndices respectivamente y devuelvan una lista de 铆ndices y un string seg煤n corresponda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "599ecea77d984abaace18d2f1cc934f1",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9,
    "execution_start": 1693859157194,
    "id": "NURlEkGjkSEf",
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "\n",
    "stoi = pass\n",
    "itos = pass\n",
    "\n",
    "# encoder: toma un string, devuelve una lista de 铆ndices\n",
    "encode = lambda s: None  # CAMBIAR\n",
    "\n",
    "# decoder: toma una lista de 铆ndices, devuelve un string\n",
    "decode = lambda l: None  # CAMBIAR\n",
    "\n",
    "# --------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "e29011090a174795a80acd43b9e368ee",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "assert encode('hola, que tal?') == [46, 53, 50, 39, 6, 1, 55, 59, 43, 1, 58, 39, 50, 12], 'Verifica que el output entregue una lista de enteros'\n",
    "assert decode(encode('hola, que tal?')) == 'hola, que tal?', 'Debe ser un string'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "488abcf1ec984a438cab8626fc6e8160",
    "deepnote_cell_type": "markdown",
    "id": "ktvBOC1qmJDY"
   },
   "source": [
    "Nuestro modelo no entiende el lenguaje directamente, sino que los representa como n煤meros. Pasamos el corpus completo a su representaci贸n de enteros, usando el `stoi` (aka _string-to-index_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "9e79dd31677a477580450a4b80e2aa95",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 136,
    "execution_start": 1693859161854,
    "id": "WAsyhejrl2X6",
    "outputId": "00a2f69e-3a81-4e2f-a0f1-89a65b6a9efb",
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "39c418201e2a4534a13ddc5527929041",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "id": "d9aOmlLVlEcr",
    "outputId": "837c4a39-03c9-4070-8f9a-495ae235dce7"
   },
   "outputs": [],
   "source": [
    "N=100\n",
    "print(f\"Texto con los primeros {N} caracteres:\\n----------------------------------------------\\n\")\n",
    "print(text[:N])\n",
    "print(\"\\n----------------------------------------------\\nSu representaci贸n como tensor de PyTorch...\\n\")\n",
    "print(data[:N])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5aa3280c539a40c7a350543d116126c6",
    "deepnote_cell_type": "markdown",
    "id": "Aqdw5-8BnVhX"
   },
   "source": [
    "## 2. Separar el dataset  y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "4ee3ee4d9f4c425e86da95a874ce263f",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 14,
    "execution_start": 1693859215823,
    "id": "zzUjG0OqnWr4",
    "outputId": "83ca4977-0452-4329-c2e5-a7c40449faf1",
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "n = int(0.9 * len(data))  # 90%\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "print(f\"--> Tama帽o del corpus de entrenamiento: {len(train_data):,} ({(train_data.shape[0] / data.shape[0]):.2f}) caracteres\")\n",
    "print(f\"--> Tama帽o del corpus de validaci贸n: {len(val_data):,} ({(val_data.shape[0] / data.shape[0]):.2f}) caracteres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "91dfd4134b1c44ba8b699996afd1cc7d",
    "deepnote_cell_type": "markdown",
    "id": "JaWNJQnzpzC8"
   },
   "source": [
    "Sobre la m茅canica de datos y etiquetas,\n",
    "\n",
    "* Accedemos a los datos a partir de \"fragmentos contextuales\"; esto es un bloque de texto en representaci贸n n煤merica de tama帽o `block_size`\n",
    "* El modelo es semi-supervisado, es decir, b煤scamos entrenar un modelo de tal forma que dado ${x}_{i:j}$ _tokens_, vamos a predecir el siguiente _token_ $x_{j+1}$\n",
    "* Las etiquetas emergen del mismo bloque contextual moviendo la ventana con un _offset_ de 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "97a1b7a307504727b77d318f9923413a",
    "deepnote_cell_type": "markdown",
    "id": "zFVaZzxuq0H3"
   },
   "source": [
    "Por ejemplo, dado un bloque de tama帽o 8,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "b4b1cc1b8e7d4b9795c52191988b8056",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 23,
    "execution_start": 1693859220379,
    "id": "ouHuc50ApdRS",
    "outputId": "212050e2-1b1b-42e1-8a9f-931c0976287c",
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "block_size = 13\n",
    "print(f\"Una bloque contextual (X, Y) ser谩:\\n\")\n",
    "print(f\"X: {[x.item() for x in data[:block_size]]}\")\n",
    "print(f\"  --> decode(X): {decode([x.item() for x in data[:block_size]])}\")\n",
    "print('------------------------------------')\n",
    "print(f\"Y: {[x.item() for x in data[1:block_size+1]]}\")\n",
    "print(f\"  --> decode(Y): {decode([y.item() for y in data[1:block_size+1]])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d2f37b21b42246a3adfb3998f07f9387",
    "deepnote_cell_type": "markdown",
    "id": "ukclPGdHwALB"
   },
   "source": [
    "Sin embago, dentro de cada bloque contextual ocupamos la informaci贸n de manera autoregresiva, generando m煤ltiple observaciones a partir de este..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "07f3c398835145b38ffa4db9f8b924e6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 17,
    "execution_start": 1693859223706,
    "id": "NBir0GCgshQH",
    "outputId": "46ed83b4-aa7a-40d7-e70e-b3690645686b",
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"Cuando el input es {context} el target es: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7ed1dfd8af584e109c9348cd1d0912db",
    "deepnote_cell_type": "markdown",
    "id": "AeRBbWV6z75E"
   },
   "source": [
    "Por lo tanto, cada bloque contextual, genera un n煤mero de observaciones igual a su tama帽o.\n",
    "\n",
    "En t茅rminos de _batches_, podemos procesar en paralelo, m煤ltiples bloques contextuales. Lo importante es que cada bloque contextual es independiente, y no hay computo que ocurra a nivel transversal, sino paralelo entre estos. No se mezclan las secuencias autoregresivas de cada contexto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "779633ce16194ccfbcc43f79bf338b7a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 265,
    "execution_start": 1693859227529,
    "id": "X3hWnI_5yp7x",
    "outputId": "a01f72b2-2644-4065-f149-e622a55790bc",
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# colocar seed como su RUT\n",
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8  # largo de ventana m谩ximo para considerar en la precisi贸n\n",
    "# Estos par谩metros se re-definir谩n para el entrenamiento final\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"Cuando el input es {context.tolist()} el target: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1889b0faf3d648409045388624948ef6",
    "deepnote_cell_type": "markdown",
    "id": "U-xAeNbk1f2E"
   },
   "source": [
    "Lo que recibir谩 la red como _input_ ser谩:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "ace2e494f0af47718468b6e75eb1dd54",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 17,
    "execution_start": 1693859236814,
    "id": "gTCL2aQY1VbI",
    "outputId": "a1b07199-d63c-4f5c-e874-86af4f43a774",
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "xb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8f4d24230cbc46af97f97d7090c150d4",
    "deepnote_cell_type": "markdown",
    "id": "OPG_QkSJ1km7"
   },
   "source": [
    "## 3. Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6e48f01409934cf88739d426f3a1b144",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Creamos un modelo base cl谩sico, para luego compararlo con nuestro Transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "79776665f2914e0dad0b035148df8a82",
    "deepnote_cell_type": "code",
    "id": "MlAT7Lnx1hyd"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # cada token lee sucesivamente los logits para el token siguiente de una lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        # idx y targets son ambos tensores de tama帽o (B,T) con elementos enteros\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx es un arreglo (B, T) de indices del contexto actual\n",
    "        for _ in range(max_new_tokens):\n",
    "            # obtener predicciones\n",
    "            logits, loss = self(idx)\n",
    "            # concentrarse en el 煤ltimo paso\n",
    "            logits = logits[:, -1, :]  # se convierte en (B, C)\n",
    "            # aplicamos softmax para obtener probabilidades\n",
    "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
    "            # samplear de la distribuci贸n\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # agregar el 铆ndice de la muestra a la secuencia actual\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d163007f6061430fa982a27a84438b23",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## 4. Self-attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0f104b88006e4923a61a73a4d2c7cf87",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "En la secci贸n anterior, vimos que cada _token_ toma una representaci贸n vectorial llamada _embeddings_.\n",
    "\n",
    "Nuestro corpus contiene $65$ caracteres 煤nicos con un _embedding_ asociado a cada _token_. La idea de representar el lenguaje en t茅rminos de tokens, y estos a su vez en vectores, es que podemos aprender estas representaciones vectoriales a partir de los datos. Sin embargo, la representaci贸n es 煤nica, y muchas veces un mismo _token_ puede tener distintos significados seg煤n su contexto. Por ejemplo:\n",
    "1. \"Te banco a morir!\"\n",
    "2. \"El banco est谩 abierto hasta las dos.\"\n",
    "\n",
    "En ambas oraciones anteriores, el token `banco` tiene un significado distinto. Se espera entonces que la representaci贸n de ese token sea distinta en ambos casos y eso lo logramos con la influencia de los tokens presentes en el mismo contexto.\n",
    "\n",
    "La idea principal de _self-attention_ es utilizar la secuencia de _embeddings_ dentro de un contexto para computar un promedio ponderado a partir de estos. Dado una secuencia de _embeddings_ de _tokens_ $x_1, \\dots, x_n$, el mecanismo de _self-attention_ (o auto-atenci贸n) produce una nueva secuencia de _embeddings_ $x'_1, \\dots, x'_n$, donde cada $x'_i$ es una combinaci贸n lineal de todos los $x_j$:\n",
    "\n",
    "$$\n",
    "x'_i = \\sum_{j=1}^{n} \\alpha_{ij} x_{j}\n",
    "$$\n",
    "\n",
    "Los coeficientes $\\alpha_{ij}$ se llaman ponderadores de atenci贸n y est谩n normalizados tal que $\\sum_{j}\\alpha_{ji}=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9e921ba45c064d5d9628b6dc9f470c9b",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "En t茅rminos sencillos, construiremos un mecanismo de comunicaci贸n entre distintos tokens dentro del bloque de contexto, que se representar谩 por una colecci贸n de ponderadores en una matriz. Esta colecci贸n de ponderadores la llamaremos matriz de atenci贸n (o self-attention) y nos permitir谩 v铆a la operaci贸n de multiplicaci贸n de matrices, agregar distintos valores dentro de un bloque contextual en una sola cantidad. Spoiler, estos pesos ser谩n data-dependientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9296b572acca4bad82f5cfc62690af5b",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Comencemos emulando la operaci贸n con pesos fijos, usaremos la parte triangular inferior de una matriz identidad de 3x3, la cual normalizaremos a nivel de fila."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "b8c36015c3a24412a5f725c06a0e08ac",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 44,
    "execution_start": 1693860540618,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# Ejemplo de juguete que ilustra como la multiplicaci贸n matricial puede ser usada para una adici贸n con pesos\n",
    "torch.manual_seed(42)\n",
    "\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "\n",
    "print('a=',a,'\\n')\n",
    "print('b=',b,'\\n')\n",
    "print('c=',c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ff4d0f0d742e4f9ba3bcb7f6e8e560ef",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Notemos que $c$ tiene en cada fila los resultados de los valores acumulados de $b$ seg煤n los ponderadores de $a$.\n",
    "\n",
    "El tensor $a$ se interpreta como una matriz de token-a-token y representa la interaci贸n/influencia del token en la posici贸n $i$ con el token de la posici贸n $j$. Dado que nuestro modelo es autoregresivo, los tokens del presente solo pueden ser influenciados por tokens pasados, o ellos mismos. Por eso las posiciones de $a$ que cumplen esta restricci贸n $i \\leq j$, son elementos que conforman la matriz triangular inferior de $a$. El resto de las posiciones no tiene influencia sobre los tokens pasados (i.e. 0).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f3c3eaff6931470ab66a89baf7c2b884",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Vamos a crear un _batch_ con datos s铆ntetico de tama帽o `B`, donde cada bloque contextual ser谩 de largo $T$, y cada _token_ que compone el contexto se representa por $C$ dimensiones (i.e. tama帽o del _embedding_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "e2e10fa5f831461daec2ca0c93b27a04",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 25,
    "execution_start": 1693861772506,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "B,T,C = 4,8,2 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] # (t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "2aa3b323c83c4ac4a4f7ea1930ca253c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 16,
    "execution_start": 1693862258062,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# Versi贸n usando softmax\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "f89fedd9c5664d448a0f73d90c8c53ca",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 14,
    "execution_start": 1693862260341,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "wei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f647ef2e2b1d4f589593fb378fe2616f",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Los ponderadores anteriores son uniformes, ahora introducimos los conceptos de _queries_ y _keys_ para ver como computar los ponderadores a partir de los datos.\n",
    "\n",
    "* Un _query_ $q(\\cdot)$ corresponde a una proyecci贸n lineal de la representaci贸n de _embeddings_ de un token particular. Por ejemplo, se proyecto $\\mathbb{R}^{C}\\rightarrow \\mathbb{R}^{H}$.\n",
    "* Los _keys_ es la matriz $K\\in\\mathbb{R}^{T\\times H}$ que contiene proyecciones lineales de todos los _embeddings_ de tokens dentro del contexto, inclu铆do el token que es el query. La proyecci贸n lineal de los _keys_ es de igual tama帽o (i.e. $H$) que la proyecci贸n del _query_.\n",
    "* Los ponderadores para cada _query_ se obtiene a partir de qu茅 tan pr贸ximo se relaciona un token respecto al resto de los token dentro de un contexto. Por ejemplo, $q(x_i) \\times K$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "a4f9611bdc5f426b87b42952cdf55d51",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://sebastianraschka.com/images/blog/2023/self-attention-from-scratch/context-vector.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://sebastianraschka.com/images/blog/2023/self-attention-from-scratch/context-vector.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "2bdc17d026094321b7b1b6b53fd3bec9",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "> b) (Bonus): Explique porqu茅 no se utilizan directamente los _embeddings_ para computar la matriz de atenci贸n previo a la normalizaci贸n, i.e. `(T,B).dot((B,T))`, en vez de usar las proyecciones $QK^\\top$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8bdb8dd7d9954b87b248303181315e57",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "> c) (Bonus): Explique los argumentos detras de escalar por $1/\\sqrt{d_k}$ referidos en el paper _[Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)_ (Vaswani 2017)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "0a0761b6973342598468b3f265e85223",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 16,
    "execution_start": 1693864851430,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# colocar seed como su RUT\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "B,T,C = 4,8,32  # batch, time, channels\n",
    "x = torch.randn(B,T,C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ff534d33b5ae46b5a252eaa2023dfa39",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Ejemplo de aplicaci贸n de m贸dulo de atenci贸n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "64725c524c18451a843b2f837bd65dcd",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)  # (B, T, 16)\n",
    "q = query(x)  # (B, T, 16)\n",
    "wei =  q @ k.transpose(-2, -1)  # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5db2feb142554dddb5ce05738c1f743e",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Observaciones:\n",
    "- Atenci贸n es un **mecanismo de comunicaci贸n**. Puede ser entendido como nodos en un grafo dirigido conect谩ndose unos con otros y agregando informaci贸n con una suma ponderada de todos los nodos que apuntan a ellos, con pesos dependientes de los datos.\n",
    "- No hay una noci贸n de espacio. Atenci贸n simplemente actua sobre el conjunto de vectores. Es por este motivo que se necesitan encoders posicionales.\n",
    "- Cada punto dentro de un batch es, desde luego, procesado de manera independiente y nunca intractua con los otros.\n",
    "- En un bloque de atenci贸n \"encoder\" basta comentar la linea que hace masking con `tril`, que hace que los tokens se comuniquen todos con todos. El bloque anterior se llama \"decoder\" porque aplica un masking triangular y se encuentre frecuentemente en configuraciones autoregresivas.\n",
    "- \"auto-atenci贸n\" (_self-attention_) s贸lo signfica que tanto _keys_ como _values_ son producidas desde la misma fuente que las _queries_. En \"atenci贸n-cruzada\" (_cross-attention_), las _queries_ vienen de $x$, pero _keys_ y _values_ vienen de otra fuente externa (como puede ser un modulo encoder).\n",
    "- Atenci贸n \"escalada\" divide `wei` por $\\frac{1}{\\sqrt{head\\_size}}$. Esto hace que cuando los input $Q$ y $K$ tengan varianza unitaria, `wei` tambi茅n tendr谩 varianza unitaria y evitar谩 la saturaci贸n de la Softmax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "833c93c83a6f42e6a9c6e3adce82a4be",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "> d) (1.5 ptos.) Cree una clase `Head` que implemente un m贸dulo de auto-atenci贸n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "e86d22f778c4464894ee70eeb6f47ae1",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "n_embd = 64  # dimensionalidad del input\n",
    "dropout = 0.0\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" Una cabeza de auto-atenci贸n \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        # ------------------------\n",
    "\n",
    "        self.key = pass  # Colocar matriz que computa estos valores desde un input\n",
    "        # E igualmente para value y query\n",
    "\n",
    "        # ------------------------\n",
    "        # HINT: cuando aplique tril, ocupe self.tril se define automaticamente\n",
    "        # al instanciar\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input size (batch, time-step, channels)\n",
    "        # output size (batch, time-step, channels)\n",
    "        B,T,C = x.shape\n",
    "        # -----------------------------------------\n",
    "\n",
    "        # Aplicar las funciones anteriores\n",
    "        k = pass  # (B,T,C)\n",
    "        q = pass  # (B,T,C)\n",
    "        v = pass  # (B,T,C)\n",
    "\n",
    "        # Computar los score de atenci贸n (\"affinities\")\n",
    "        wei = pass  # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = pass  # (B, T, T)\n",
    "        wei = pass  # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "\n",
    "        # Adici贸n (con pesos) de las atenciones\n",
    "        out = pass  # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "    \n",
    "        # --------------------------------------\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "96c2b9cefd6b453cb437392b7f03f5d4",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "La arquitectura decoder del paper Transformer implementa varias versiones de _self-attention_ en paralelo, cada una es una \"c谩beza de atenci贸n\", y estas concatenan sus resultados en un modulo conocido como `MultiHeadAttention`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "214c8ece545f4817b8561dfae0db408a",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" M煤ltiples cabezas de auto-atenci贸n en paralelo \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5d5e70b87ba948e6b2db556e91caeac7",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "> e) (0.75 pto.) Implemente una clase `FeedForward` como se describe en el art铆culo [\"Attention is all you need, Vaswani et al.\"](https://arxiv.org/pdf/1706.03762.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "2bd2438a5180464c873da561e6a8527c",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" \n",
    "        Implementar FeedForward descrita en secci贸n:\n",
    "         \"3.3 Position-wise Feed-Fordward Networks\", paper\n",
    "         \"Attention is All You Need\"\n",
    "        https://arxiv.org/pdf/1706.03762.pdf\n",
    "        \n",
    "        in: n_embd\n",
    "        out: n_embd\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            # -------------------\n",
    "\n",
    "            # Defina las operaciones a razlizar, secuencialmente al input\n",
    "            # Recuerde que la primera capa aumenta el tama帽o del input en un facor de 4\n",
    "            # Luego en la 煤ltima volvemos a la dimensionalidad inicial\n",
    "\n",
    "            # ------------------\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "fd893f1e2d6842b08beb90dd1091e678",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://jalammar.github.io/images/gpt2/gpt2-transformer-block-vectors-2.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"http://jalammar.github.io/images/gpt2/gpt2-transformer-block-vectors-2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e0384b1c93274e7abfb20d5627b2958c",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "> f) (0.5 ptos.) Explique la relaci贸n entre los hiperpar谩metros `n_head` y `head_size` de la clase `MultiHeadAttention`. Piense en su rol dentro del bloque decoder (i.e. atenci贸n + feedforward)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respuesta:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora procederemos a armar la clase que implemente un bloque de Decoder. N贸tese que en realidad estamos codificando texto con este bloque, pero esto corresponde a la parte \"Decoder\" del Transformer original, por ende guardamos esa nomenclatura. La motivaci贸n del uso del decoder es modelar el texto de maner auto-regresiva, que es ideal para la generaci贸n de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.stack.imgur.com/bWnx0.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://i.stack.imgur.com/bWnx0.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "708d555c66ac4f4a940e82ab2251cb76",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "> g) (0.75 ptos.) Complete el paso _forward_ de la clase `DecoderBlock`. Recuerde en particula incorporar las conexiones residuales (_skip connections_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "8a013f2aceba4d7eb70390a12f21c308",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"  BloqueTransformer: COMUNICACIN seguida de CMPUTO \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: dimensi贸n de embeddings, n_head: n煤mero de cabezas de atenci贸n\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Hint: aplique las capas de normalizaci贸n siempre antes de otra capa (Pre-LN varaint)\n",
    "        # Ver: https://magazine.sebastianraschka.com/p/why-the-original-transformer-figure\n",
    "        # ---------------------\n",
    "\n",
    "        x = pass  # completar\n",
    "\n",
    "        # ----------------------\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "cd75ed98e96247ffa253556488b53e4e",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## 5. Modelo GPT: Juntando todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00e10b6c07f5442b95e5c2b0819edc0a",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "> h) (1 pto.) Complete el c贸digo de la clase `GPTLanguageModel`procesando adecuadamente el input del modelo. Complete adem谩s el m茅todo `generate` para samplear elementos que completen auto-regresivamente una secuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "88ed14ab007b4feea097aaa558f1cb73",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "class GPTLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # cada token lee directamente los logits para el token siguiente de una lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[DecoderBlock(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx y targets son ambos tensores (B,T) de enteros\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "\n",
    "        # -----------------------------\n",
    "\n",
    "        x = pass  # DEFINIR x, con shape (B,T,C)\n",
    "\n",
    "        # procesar x...\n",
    "\n",
    "        logits = pass  # CALCULAR logits (B,T,vocab_size)\n",
    "\n",
    "        # -------------------------------\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx es un arreglo (B, T) de 铆ndices en el contexto actual\n",
    "        for _ in range(max_new_tokens):\n",
    "            # restringir idx a los 煤ltimos block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # obtener las predicciones\n",
    "            logits, loss = self(idx_cond)\n",
    "            # enfocarse s贸lo en el 煤ltimo paso\n",
    "            logits = logits[:, -1, :]  # se convierte en size (B, C)\n",
    "            # ------------------------------------------------------------\n",
    "\n",
    "            # aplicar softmax para obtener las probabilidades\n",
    "            probs = pass  # tensor de dimensionalidad (B, C)\n",
    "\n",
    "            # definir una distribuci贸n apropiada para samplear usando las probabilidades\n",
    "            idx_next = pass  # tensor de 铆ndices de dim (B, 1)\n",
    "\n",
    "            # adjuntar el token generado a la secuencia (actualizando idx)\n",
    "            idx = pass  # tensor resultante de dimensionalidad (B, T+1)\n",
    "            \n",
    "            # ------------------------------------------------------------\n",
    "\n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "56fa2d0e8f424060841dfb5a0793b8e8",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Definimos hiperpar谩metros (global variables, esto se puede hacer mucho mejor)\n",
    "\n",
    "batch_size = 16 # cuantos secuencias de fragmentos del corpus procesaremos de manera independiente (aka B)?\n",
    "block_size = 128 # cu谩l ser谩 el tama帽o del bloque de contexto a considerar para predecir (aka T)?\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4  # modelo de tama帽o peque帽o probar esta lr por defecto\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 384  # se debe considerar en conjunto con n_head, seg煤n an谩lisis en (f)\n",
    "n_head = 6    # se debe considerar en conjunto con n_embd, seg煤n an谩lisis en (f)\n",
    "n_layer = 6  \n",
    "dropout = 0.2\n",
    "\n",
    "\n",
    "model = GPTLanguageModel()\n",
    "model.to(device)\n",
    "\n",
    "# printear el n煤mero de par谩metros del modelo\n",
    "print('N煤mero de par谩metros del modelo:', sum(p.numel() for p in model.parameters())/1e6, 'millones')\n",
    "\n",
    "# definir el optimizador de PyTorch\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiremos una funci贸n para generar batches de secuencias a partir de nuestro corpus de entrenamiento o validaci贸n. Adem谩s de una funci贸n para obtener estimaciones de la funci贸n de costo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos un \"DataLoader\"\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# definimos una funci贸n para obtener estimados de nuestras\n",
    "# p茅rdidas tanto en los conjuntos de train como en val\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primer sanity check, obtener batches con dimensiones correctas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifiquemos que las dimensiones sean correctas\n",
    "xb, yb = get_batch('train')\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segundo sanity check, verificar que la data fluya correctamente por el modelo,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifiquemos que el forwardpass del modelo no tenga problemas\n",
    "model(xb)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6cd551bb57f54567a9780b868c2081e7",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "> i) (1 pto.) Complete el bucle de entrenamiento usando comandos de `pytorch.optimize` conocidos. Ejecute el entrenamiento (se recomienda dejarlo corriendo e ir hacer algo m谩s...). Corrobore que se modelo es capaz de generar texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "faa0a3b9283247f1a8cf6d6b8d599959",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# colocar RUT como semilla\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "# comenzamos el training loop...\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # de vez en cuando evaluar la loss en los conjuntos de train y evaluaci贸n\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # samplear un batch de datos\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "\n",
    "    # ----------------------------------------\n",
    "\n",
    "    # activar el optimizador y hacer el paso backward con el resultado de la funci贸n loss\n",
    "\n",
    "    # ----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5a8d031142ab45d48e9b9eeb81f6b2f7",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## 6. Generando secuencias de texto con el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "9e6d66e2a3ba49a4ae3c23d4e65d57df",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Generar usando el modelo\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))\n",
    "\n",
    "# Para escribir en un archivo\n",
    "# open('output.txt', 'w').write(decode(m.generate(context, max_new_tokens=10000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> j) (bonus) Define un training loop para el baseline (modelo bi-grama). Entr茅nelo usando un npumero similar de 茅pocas y compare las losses y generaci贸n de texto con su modelo anterior."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "409cf1afb7654c8282dccc46f347e63f",
  "deepnote_persisted_session": {
   "createdAt": "2023-09-04T22:31:43.624Z"
  },
  "kernelspec": {
   "display_name": "aml_env",
   "language": "python",
   "name": "aml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
