{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"3ec1cec624ef406c8f6a8d3cb7b93d46","deepnote_cell_type":"markdown","id":"e4Pr6pv5ie50"},"source":["**MDS7203 Modelos Generativos Profundos, Primavera 2023**\n","\n","# Laboratorio 2: Modelos Autoregresivos\n","\n","**Profesor**: Felipe Tobar, **Auxiliares**: Crist√≥bal Alc√°zar, Camilo Carvajal Reyes, **Ayudante**: Joaqu√≠n Barcel√≥.\n","\n","**Fecha de entrega**: viernes 29 de septiembre 2023"]},{"cell_type":"markdown","metadata":{"cell_id":"38cd31c023b047f080018f94f24927e8","deepnote_cell_type":"markdown"},"source":["**Nombre: COLOCAR AQU√ç SU NOMBRE**"]},{"cell_type":"markdown","metadata":{"cell_id":"279c16d9f94a4b5dbe45f9f4f6ff6f07","deepnote_cell_type":"markdown"},"source":["**Instrucciones**: El presente notebook contiene enunciado e instrucciones para la realizaci√≥n del laboratorio. Usted deber√° completar los c√≥digos (en este archivo o en una copia del mismo) donde se le pida hacerlo. Usted deber√° entregar el notebook con sus respuestas, cumpliendo lo siguiente:\n","\n","- Los comentarios en c√≥digo deben ser concisos pero claros. No se evaluar√°n sub-preguntas donde solo exista c√≥digo sin comentarios pertinentes.\n","- El c√≥digo debe ser ordenado y ejectuable. No se evaluar√°n notebooks o scripts que generen errores en su ejecuci√≥n. Se aconseja resetear la kernel y corroborar la correcta execuci√≥n de todas las celdas antes de ejecutar el entrenamiento de su modelo.\n","- Si bien se aconseja el uso de internet y otras herramientas para asistir su trabajo, asi como discusiones con el ED y estudiantes, el c√≥digo que entregue debe ser de su autor√≠a.\n","\n","Algunos links √∫tiles:\n","\n","* [Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)\n","* [GPT2, original blog post](https://openai.com/research/better-language-models)\n"]},{"cell_type":"markdown","metadata":{"cell_id":"40d3aa47f3204ca888f874beb273d9f5","deepnote_cell_type":"text-cell-h3","formattedRanges":[]},"source":["### Resumen de preguntas"]},{"cell_type":"markdown","metadata":{"cell_id":"14369c673f3049a19e647a78a00686d4","deepnote_cell_type":"text-cell-todo","formattedRanges":[]},"source":["- [ ] a) (0,5 ptos.) Definici√≥n de diccionarios para vocabulario"]},{"cell_type":"markdown","metadata":{"cell_id":"c3ae5920aed6440ea4c012068c08bb8b","checked":false,"deepnote_cell_type":"text-cell-todo","formattedRanges":[]},"source":["- [ ] b) (bonus) Utilizaci√≥n de embeddings previo a la normalizaci√≥n"]},{"cell_type":"markdown","metadata":{"cell_id":"d259ba9b76b74b2e8eb0132b06f7f31c","checked":false,"deepnote_cell_type":"text-cell-todo","formattedRanges":[]},"source":["- [ ] c) (bonus) Escalamiento por $1/\\sqrt{d_k}$."]},{"cell_type":"markdown","metadata":{"cell_id":"14547d4ff1564ceca8f1133b2bf3831f","checked":false,"deepnote_cell_type":"text-cell-todo","formattedRanges":[]},"source":["- [ ] d) (1.5 ptos.) Creaci√≥n de clase `Head`."]},{"cell_type":"markdown","metadata":{"cell_id":"806e04b64a5f4e8c9c46b8addb61da30","checked":false,"deepnote_cell_type":"text-cell-todo","formattedRanges":[]},"source":["- [ ] e) (1 pto.) Implementaci√≥n de clase `FeedForward`."]},{"cell_type":"markdown","metadata":{"cell_id":"af2c2194e9e94407b2ed8d38ac7dd9c5","checked":false,"deepnote_cell_type":"text-cell-todo","formattedRanges":[]},"source":["- [ ] f) (0.5 ptos.) Relaci√≥n entre hiper-par√°metros n_head y head_size."]},{"cell_type":"markdown","metadata":{"cell_id":"9cec4a573e824ff2a535781db9773328","checked":false,"deepnote_cell_type":"text-cell-todo","formattedRanges":[]},"source":["- [ ] g) (0.5 ptos.) Forward pass en `EncoderBlock`."]},{"cell_type":"markdown","metadata":{"cell_id":"33851255223c4c569a4ef98add7b0b4f","checked":false,"deepnote_cell_type":"text-cell-todo","formattedRanges":[]},"source":["- [ ] h) (1 pto.) Implementaci√≥n clase `GPTLM`."]},{"cell_type":"markdown","metadata":{"cell_id":"273f32755bf446cba8132463ead5c3ac","checked":false,"deepnote_cell_type":"text-cell-todo","formattedRanges":[]},"source":["- [ ] g) (1 pto.) Training loop."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"3381cfa7678849408eeaf9aedb7fb2d1","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":5134,"execution_start":1693917871424,"id":"xIPkmAHJmC9s","source_hash":null},"outputs":[{"name":"stderr","output_type":"stream","text":["/shared-libs/python3.9/py/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as F"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"2bd1045c4e41414b88df0bae08b56b58","colab":{"base_uri":"https://localhost:8080/"},"deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":474,"execution_start":1693859116039,"id":"CGoaBP7mygL4","outputId":"921a9201-f250-4b10-a82a-280ac6ed6a03","source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["/bin/bash: nvidia-smi: command not found\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"cell_id":"a607d5c593c64504a2c445b78a01b637","deepnote_cell_type":"markdown","id":"O54vJC-DjbMe"},"source":["## 1. Corpus üìñ"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"5126c2297ea643289976bf6c9b1cd627","colab":{"base_uri":"https://localhost:8080/"},"deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":16286,"execution_start":1693864714844,"id":"0lsVnPMTibNf","outputId":"b837e01a-1c86-4215-9c4e-b4512a648dd3","source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["--2023-09-04 21:58:34--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1115394 (1.1M) [text/plain]\n","Saving to: ‚Äòinput.txt.1‚Äô\n","\n","input.txt.1         100%[===================>]   1.06M  --.-KB/s    in 0.005s  \n","\n","2023-09-04 21:58:50 (205 MB/s) - ‚Äòinput.txt.1‚Äô saved [1115394/1115394]\n","\n"]}],"source":["!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"23f881bed52248f8bfd4204bbdf4f3d1","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":19,"execution_start":1693864731107,"id":"oC8C6LkJi21K","source_hash":null},"outputs":[],"source":["with open('input.txt', 'r', encoding='utf-8') as file:\n","    text = file.read()\n","\n","print(f\"Tama√±o del corpus: {len(text):,} caracteres\")"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"10a13a6c0fd849b584a6ab3a4f5991e6","colab":{"base_uri":"https://localhost:8080/"},"deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":21,"execution_start":1693859154739,"id":"Z-IuIqKHj0zL","outputId":"fa8f8d5c-d2cb-463f-f0aa-37ddf0eddc79","source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"," !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n","65\n"]}],"source":["chars = sorted(list(set(text)))\n","vocab_size = len(chars)\n","print(''.join(chars))\n","print(vocab_size)"]},{"cell_type":"markdown","metadata":{"cell_id":"063a10ca987f4b479fb3b53b92f2ad52","deepnote_cell_type":"markdown"},"source":["> a) (0.5 ptos.) Dada una lista de ordenada de caracteres, defina:\n","> - stoi: un diccionario caracter -> √≠ndice\n","> - itos: un diccionario √≠ndice -> caracter\n","> Con lo anterior, defina dos funciones encode y decode que tomen un string y una lista de √≠ndices respectivamente y devuelvan una lista de √≠ndices y un string seg√∫n corresponda."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"599ecea77d984abaace18d2f1cc934f1","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":9,"execution_start":1693859157194,"id":"NURlEkGjkSEf","source_hash":null},"outputs":[],"source":["# --------------------------------------------\n","\n","stoi = pass\n","itos = pass\n","\n","# encoder: toma un string, devuelve una lista de √≠ndices\n","encode = lambda s: None  # CAMBIAR\n","\n","# decoder: toma una lista de √≠ndices, devuelve un string\n","decode = lambda l: None  # CAMBIAR\n","\n","# --------------------------------------------"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"e29011090a174795a80acd43b9e368ee","deepnote_cell_type":"code"},"outputs":[],"source":["assert encode('hola, que tal?') == [46, 53, 50, 39, 6, 1, 55, 59, 43, 1, 58, 39, 50, 12], 'Verifica que el output entregue una lista de enteros'\n","assert decode(encode('hola, que tal?')) == 'hola, que tal?', 'Debe ser un string'"]},{"cell_type":"markdown","metadata":{"cell_id":"488abcf1ec984a438cab8626fc6e8160","deepnote_cell_type":"markdown","id":"ktvBOC1qmJDY"},"source":["Nuestro modelo no entiende el lenguaje directamente, sino que los representa como n√∫meros. Pasamos el corpus completo a su representaci√≥n de enteros, usando el `stoi` (aka _string-to-index_)."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"9e79dd31677a477580450a4b80e2aa95","colab":{"base_uri":"https://localhost:8080/"},"deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":136,"execution_start":1693859161854,"id":"WAsyhejrl2X6","outputId":"00a2f69e-3a81-4e2f-a0f1-89a65b6a9efb","source_hash":null},"outputs":[{"data":{"text/plain":["torch.Size([1115394])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["data = torch.tensor(encode(text), dtype=torch.long)\n","data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"39c418201e2a4534a13ddc5527929041","colab":{"base_uri":"https://localhost:8080/"},"deepnote_cell_type":"code","id":"d9aOmlLVlEcr","outputId":"837c4a39-03c9-4070-8f9a-495ae235dce7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Texto con los primeros 100 caracteres:\n","----------------------------------------------\n","\n","First Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You\n","\n","----------------------------------------------\n","Su representaci√≥n como tensor de PyTorch...\n","\n","tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n","        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n","         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n","        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n","         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n","        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"]}],"source":["N=100\n","print(f\"Texto con los primeros {N} caracteres:\\n----------------------------------------------\\n\")\n","print(text[:N])\n","print(\"\\n----------------------------------------------\\nSu representaci√≥n como tensor de PyTorch...\\n\")\n","print(data[:N])"]},{"cell_type":"markdown","metadata":{"cell_id":"5aa3280c539a40c7a350543d116126c6","deepnote_cell_type":"markdown","id":"Aqdw5-8BnVhX"},"source":["## 2. Separar el dataset üî® y üéì"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"4ee3ee4d9f4c425e86da95a874ce263f","colab":{"base_uri":"https://localhost:8080/"},"deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":14,"execution_start":1693859215823,"id":"zzUjG0OqnWr4","outputId":"83ca4977-0452-4329-c2e5-a7c40449faf1","source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["--> Tama√±o del corpus de entrenamiento: 1,003,854 (0.90) caracteres\n","--> Tama√±o del corpus de validaci√≥n: 111,540 (0.10) caracteres\n"]}],"source":["n = int(0.9 * len(data))  # 90%\n","train_data = data[:n]\n","val_data = data[n:]\n","print(f\"--> Tama√±o del corpus de entrenamiento: {len(train_data):,} ({(train_data.shape[0] / data.shape[0]):.2f}) caracteres\")\n","print(f\"--> Tama√±o del corpus de validaci√≥n: {len(val_data):,} ({(val_data.shape[0] / data.shape[0]):.2f}) caracteres\")"]},{"cell_type":"markdown","metadata":{"cell_id":"91dfd4134b1c44ba8b699996afd1cc7d","deepnote_cell_type":"markdown","id":"JaWNJQnzpzC8"},"source":["Sobre la m√©canica de datos y etiquetas,\n","\n","* Accedemos a los datos a partir de \"fragmentos contextuales\"; esto es un bloque de texto en representaci√≥n n√∫merica de tama√±o `block_size`\n","* El modelo es semi-supervisado, es decir, b√∫scamos entrenar un modelo de tal forma que dado ${x}_{i:j}$ _tokens_, vamos a predecir el siguiente _token_ $x_{j+1}$\n","* Las etiquetas emergen del mismo bloque contextual moviendo la ventana con un _offset_ de 1."]},{"cell_type":"markdown","metadata":{"cell_id":"97a1b7a307504727b77d318f9923413a","deepnote_cell_type":"markdown","id":"zFVaZzxuq0H3"},"source":["Por ejemplo, dado un bloque de tama√±o 8,\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"b4b1cc1b8e7d4b9795c52191988b8056","colab":{"base_uri":"https://localhost:8080/"},"deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":23,"execution_start":1693859220379,"id":"ouHuc50ApdRS","outputId":"212050e2-1b1b-42e1-8a9f-931c0976287c","source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["Una bloque contextual (X, Y) ser√°:\n","\n","X: [18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52]\n","  --> decode(X): First Citizen\n","------------------------------------\n","Y: [47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10]\n","  --> decode(Y): irst Citizen:\n"]}],"source":["block_size = 13\n","print(f\"Una bloque contextual (X, Y) ser√°:\\n\")\n","print(f\"X: {[x.item() for x in data[:block_size]]}\")\n","print(f\"  --> decode(X): {decode([x.item() for x in data[:block_size]])}\")\n","print('------------------------------------')\n","print(f\"Y: {[x.item() for x in data[1:block_size+1]]}\")\n","print(f\"  --> decode(Y): {decode([y.item() for y in data[1:block_size+1]])}\")"]},{"cell_type":"markdown","metadata":{"cell_id":"d2f37b21b42246a3adfb3998f07f9387","deepnote_cell_type":"markdown","id":"ukclPGdHwALB"},"source":["Sin embago, dentro de cada bloque contextual ocupamos la informaci√≥n de manera autoregresiva, generando m√∫ltiple observaciones a partir de este..."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"07f3c398835145b38ffa4db9f8b924e6","colab":{"base_uri":"https://localhost:8080/"},"deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":17,"execution_start":1693859223706,"id":"NBir0GCgshQH","outputId":"46ed83b4-aa7a-40d7-e70e-b3690645686b","source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["Cuando el input es tensor([18]) el target es: 47\n","Cuando el input es tensor([18, 47]) el target es: 56\n","Cuando el input es tensor([18, 47, 56]) el target es: 57\n","Cuando el input es tensor([18, 47, 56, 57]) el target es: 58\n","Cuando el input es tensor([18, 47, 56, 57, 58]) el target es: 1\n","Cuando el input es tensor([18, 47, 56, 57, 58,  1]) el target es: 15\n","Cuando el input es tensor([18, 47, 56, 57, 58,  1, 15]) el target es: 47\n","Cuando el input es tensor([18, 47, 56, 57, 58,  1, 15, 47]) el target es: 58\n","Cuando el input es tensor([18, 47, 56, 57, 58,  1, 15, 47, 58]) el target es: 47\n","Cuando el input es tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47]) el target es: 64\n","Cuando el input es tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64]) el target es: 43\n","Cuando el input es tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43]) el target es: 52\n","Cuando el input es tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52]) el target es: 10\n"]}],"source":["x = train_data[:block_size]\n","y = train_data[1:block_size+1]\n","for t in range(block_size):\n","    context = x[:t+1]\n","    target = y[t]\n","    print(f\"Cuando el input es {context} el target es: {target}\")"]},{"cell_type":"markdown","metadata":{"cell_id":"7ed1dfd8af584e109c9348cd1d0912db","deepnote_cell_type":"markdown","id":"AeRBbWV6z75E"},"source":["Por lo tanto, cada bloque contextual, genera un n√∫mero de observaciones igual a su tama√±o.\n","\n","En t√©rminos de _batches_, podemos procesar en paralelo, m√∫ltiples bloques contextuales. Lo importante es que cada bloque contextual es independiente, y no hay computo que ocurra a nivel transversal, sino paralelo entre estos. No se mezclan las secuencias autoregresivas de cada contexto."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"779633ce16194ccfbcc43f79bf338b7a","colab":{"base_uri":"https://localhost:8080/"},"deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":265,"execution_start":1693859227529,"id":"X3hWnI_5yp7x","outputId":"a01f72b2-2644-4065-f149-e622a55790bc","source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["inputs:\n","torch.Size([4, 8])\n","tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n","        [44, 53, 56,  1, 58, 46, 39, 58],\n","        [52, 58,  1, 58, 46, 39, 58,  1],\n","        [25, 17, 27, 10,  0, 21,  1, 54]])\n","targets:\n","torch.Size([4, 8])\n","tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n","        [53, 56,  1, 58, 46, 39, 58,  1],\n","        [58,  1, 58, 46, 39, 58,  1, 46],\n","        [17, 27, 10,  0, 21,  1, 54, 39]])\n","----\n","Cuando el input es [24] el target: 43\n","Cuando el input es [24, 43] el target: 58\n","Cuando el input es [24, 43, 58] el target: 5\n","Cuando el input es [24, 43, 58, 5] el target: 57\n","Cuando el input es [24, 43, 58, 5, 57] el target: 1\n","Cuando el input es [24, 43, 58, 5, 57, 1] el target: 46\n","Cuando el input es [24, 43, 58, 5, 57, 1, 46] el target: 43\n","Cuando el input es [24, 43, 58, 5, 57, 1, 46, 43] el target: 39\n","Cuando el input es [44] el target: 53\n","Cuando el input es [44, 53] el target: 56\n","Cuando el input es [44, 53, 56] el target: 1\n","Cuando el input es [44, 53, 56, 1] el target: 58\n","Cuando el input es [44, 53, 56, 1, 58] el target: 46\n","Cuando el input es [44, 53, 56, 1, 58, 46] el target: 39\n","Cuando el input es [44, 53, 56, 1, 58, 46, 39] el target: 58\n","Cuando el input es [44, 53, 56, 1, 58, 46, 39, 58] el target: 1\n","Cuando el input es [52] el target: 58\n","Cuando el input es [52, 58] el target: 1\n","Cuando el input es [52, 58, 1] el target: 58\n","Cuando el input es [52, 58, 1, 58] el target: 46\n","Cuando el input es [52, 58, 1, 58, 46] el target: 39\n","Cuando el input es [52, 58, 1, 58, 46, 39] el target: 58\n","Cuando el input es [52, 58, 1, 58, 46, 39, 58] el target: 1\n","Cuando el input es [52, 58, 1, 58, 46, 39, 58, 1] el target: 46\n","Cuando el input es [25] el target: 17\n","Cuando el input es [25, 17] el target: 27\n","Cuando el input es [25, 17, 27] el target: 10\n","Cuando el input es [25, 17, 27, 10] el target: 0\n","Cuando el input es [25, 17, 27, 10, 0] el target: 21\n","Cuando el input es [25, 17, 27, 10, 0, 21] el target: 1\n","Cuando el input es [25, 17, 27, 10, 0, 21, 1] el target: 54\n","Cuando el input es [25, 17, 27, 10, 0, 21, 1, 54] el target: 39\n"]}],"source":["torch.manual_seed(1337)\n","batch_size = 4 # how many independent sequences will we process in parallel?\n","block_size = 8 # what is the maximum context length for predictions?\n","\n","def get_batch(split):\n","    # generate a small batch of data of inputs x and targets y\n","    data = train_data if split == 'train' else val_data\n","    ix = torch.randint(len(data) - block_size, (batch_size,))\n","    x = torch.stack([data[i:i+block_size] for i in ix])\n","    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n","    return x, y\n","\n","xb, yb = get_batch('train')\n","print('inputs:')\n","print(xb.shape)\n","print(xb)\n","print('targets:')\n","print(yb.shape)\n","print(yb)\n","\n","print('----')\n","\n","for b in range(batch_size): # batch dimension\n","    for t in range(block_size): # time dimension\n","        context = xb[b, :t+1]\n","        target = yb[b,t]\n","        print(f\"Cuando el input es {context.tolist()} el target: {target}\")"]},{"cell_type":"markdown","metadata":{"cell_id":"1889b0faf3d648409045388624948ef6","deepnote_cell_type":"markdown","id":"U-xAeNbk1f2E"},"source":["Lo que recibir√° la red como _input_ ser√°:"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"ace2e494f0af47718468b6e75eb1dd54","colab":{"base_uri":"https://localhost:8080/"},"deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":17,"execution_start":1693859236814,"id":"gTCL2aQY1VbI","outputId":"a1b07199-d63c-4f5c-e874-86af4f43a774","source_hash":null},"outputs":[{"data":{"text/plain":["tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n","        [44, 53, 56,  1, 58, 46, 39, 58],\n","        [52, 58,  1, 58, 46, 39, 58,  1],\n","        [25, 17, 27, 10,  0, 21,  1, 54]])"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["xb"]},{"cell_type":"markdown","metadata":{"cell_id":"8f4d24230cbc46af97f97d7090c150d4","deepnote_cell_type":"markdown","id":"OPG_QkSJ1km7"},"source":["## 3. Baseline"]},{"cell_type":"markdown","metadata":{"cell_id":"6e48f01409934cf88739d426f3a1b144","deepnote_cell_type":"markdown"},"source":["Creamos un modelo base cl√°sico, para luego compararlo con nuestro Transformer."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"79776665f2914e0dad0b035148df8a82","deepnote_cell_type":"code","id":"MlAT7Lnx1hyd"},"outputs":[],"source":["torch.manual_seed(1337)\n","\n","class BigramLanguageModel(nn.Module):\n","\n","    def __init__(self, vocab_size):\n","        super().__init__()\n","        # cada token lee sucesivamente los logits para el token siguiente de una lookup table\n","        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n","\n","    def forward(self, idx, targets=None):\n","\n","        # idx y targets son ambos tensores de tama√±o (B,T) con elementos enteros\n","        logits = self.token_embedding_table(idx) # (B,T,C)\n","\n","        if targets is None:\n","            loss = None\n","        else:\n","            B, T, C = logits.shape\n","            logits = logits.view(B*T, C)\n","            targets = targets.view(B*T)\n","            loss = F.cross_entropy(logits, targets)\n","\n","        return logits, loss\n","\n","    def generate(self, idx, max_new_tokens):\n","        # idx es un arreglo (B, T) de indices del contexto actual\n","        for _ in range(max_new_tokens):\n","            # obtener predicciones\n","            logits, loss = self(idx)\n","            # concentrarse en el √∫ltimo paso\n","            logits = logits[:, -1, :]  # se convierte en (B, C)\n","            # aplicamos softmax para obtener probabilidades\n","            probs = F.softmax(logits, dim=-1)  # (B, C)\n","            # samplear de la distribuci√≥n\n","            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n","            # agregar el √≠ndice de la muestra a la secuencia actual\n","            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n","        return idx\n","\n","m = BigramLanguageModel(vocab_size)\n","logits, loss = m(xb, yb)\n","print(logits.shape)\n","print(loss)\n","\n","print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n"]},{"cell_type":"markdown","metadata":{"cell_id":"d163007f6061430fa982a27a84438b23","deepnote_cell_type":"text-cell-h2","formattedRanges":[]},"source":["## 4. Self-attention"]},{"cell_type":"markdown","metadata":{"cell_id":"0f104b88006e4923a61a73a4d2c7cf87","deepnote_cell_type":"markdown"},"source":["En la secci√≥n anterior, vimos que cada _token_ toma una representaci√≥n vectorial llamada _embeddings_.\n","\n","Nuestro corpus contiene $65$ caracteres √∫nicos con un _embedding_ asociado a cada _token_. La idea de representar el lenguaje en t√©rminos de tokens, y estos a su vez en vectores, es que podemos aprender estas representaciones vectoriales a partir de los datos. Sin embargo, la representaci√≥n es √∫nica, y muchas veces un mismo _token_ puede tener distintos significados seg√∫n su contexto. [INSERTAR EJEMPLO].\n","\n","La idea principal de _self-attention_ es utilizar la secuencia de _embeddings_ dentro de un contexto para computar un promedio ponderado a partir de estos. Dado una secuencia de _embeddings_ de _tokens_ $x_1, \\dots, x_n$, el mecanismo de _self-attention_ (o auto-atenci√≥n) produce una nueva secuencia de _embeddings_ $x'_1, \\dots, x'_n$, donde cada $x'_i$ es una combinaci√≥n lineal de todos los $x_j$:\n","\n","$$\n","x'_i = \\sum_{j=1}^{n} \\alpha_{ij} x_{j}\n","$$\n","\n","Los coeficientes $\\alpha_{ij}$ se llaman ponderadores de atenci√≥n y est√°n normalizados tal que $\\sum_{j}\\alpha_{ji}=1$."]},{"cell_type":"markdown","metadata":{"cell_id":"9e921ba45c064d5d9628b6dc9f470c9b","deepnote_cell_type":"text-cell-p","formattedRanges":[]},"source":["En t√©rminos sencillos, construiremos un mecanismo de comunicaci√≥n entre distintos tokens dentro del bloque de contexto, que se representar√° por una colecci√≥n de ponderadores en una matriz. Esta colecci√≥n de ponderadores la llamaremos matriz de atenci√≥n (o self-attention) y nos permitir√° v√≠a la operaci√≥n de multiplicaci√≥n de matrices, agregar distintos valores dentro de un bloque contextual en una sola cantidad. Spoiler, estos pesos ser√°n data-dependientes."]},{"cell_type":"markdown","metadata":{"cell_id":"9296b572acca4bad82f5cfc62690af5b","deepnote_cell_type":"text-cell-p","formattedRanges":[]},"source":["Comencemos emulando la operaci√≥n con pesos fijos, usaremos la parte triangular inferior de una matriz identidad de 3x3, la cual normalizaremos a nivel de fila."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"b8c36015c3a24412a5f725c06a0e08ac","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":44,"execution_start":1693860540618,"source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["a=\n","tensor([[1.0000, 0.0000, 0.0000],\n","        [0.5000, 0.5000, 0.0000],\n","        [0.3333, 0.3333, 0.3333]])\n","--\n","b=\n","tensor([[2., 7.],\n","        [6., 4.],\n","        [6., 5.]])\n","--\n","c=\n","tensor([[2.0000, 7.0000],\n","        [4.0000, 5.5000],\n","        [4.6667, 5.3333]])\n"]}],"source":["# Ejemplo de juguete que ilustra como la multiplicaci√≥n matricial puede ser usada para una adici√≥n con pesos\n","torch.manual_seed(42)\n","\n","a = torch.tril(torch.ones(3, 3))\n","a = a / torch.sum(a, 1, keepdim=True)\n","b = torch.randint(0,10,(3,2)).float()\n","c = a @ b\n","\n","print('a=',a,'\\n')\n","print('b=',b,'\\n')\n","print('c=',c)"]},{"cell_type":"markdown","metadata":{"cell_id":"ff4d0f0d742e4f9ba3bcb7f6e8e560ef","deepnote_cell_type":"markdown"},"source":["Notemos que $c$ tiene en cada fila los resultados de los valores acumulados de $b$ seg√∫n los ponderadores de $a$.\n","\n","Pregunta: si $b$ es un tensor de $3\\times 2$, que representa 2 bloques contextuales de 3 tokens (piense en los contextos `yo quiero manjar` y `ma√±ana es lunes`). C√≥mo se interpreta que $a$ sea un tensor de $3\n","\\times 3$ triangular inferior dentro de un modelo autoregresivo?\n"]},{"cell_type":"markdown","metadata":{"cell_id":"f3c3eaff6931470ab66a89baf7c2b884","deepnote_cell_type":"markdown"},"source":["Vamos a crear un _batch_ con datos s√≠ntetico de tama√±o `B`, donde cada bloque contextual ser√° de largo $T$, y cada _token_ que compone el contexto se representa por $C$ dimensiones (i.e. tama√±o del _embedding_)."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"e2e10fa5f831461daec2ca0c93b27a04","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":25,"execution_start":1693861772506,"source_hash":null},"outputs":[{"data":{"text/plain":["torch.Size([4, 8, 2])"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["torch.manual_seed(1337)\n","\n","B,T,C = 4,8,2 # batch, time, channels\n","x = torch.randn(B,T,C)\n","x.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"2aa3b323c83c4ac4a4f7ea1930ca253c","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":16,"execution_start":1693862258062,"source_hash":null},"outputs":[{"data":{"text/plain":["False"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["# Versi√≥n usando softmax\n","tril = torch.tril(torch.ones(T, T))\n","wei = torch.zeros((T,T))\n","wei = wei.masked_fill(tril == 0, float('-inf'))\n","wei = F.softmax(wei, dim=-1)\n","xbow3 = wei @ x\n","torch.allclose(xbow, xbow3)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"f89fedd9c5664d448a0f73d90c8c53ca","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":14,"execution_start":1693862260341,"source_hash":null},"outputs":[{"data":{"text/plain":["tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n","        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n","        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n","        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["wei"]},{"cell_type":"markdown","metadata":{"cell_id":"f647ef2e2b1d4f589593fb378fe2616f","deepnote_cell_type":"markdown"},"source":["Los ponderadores anteriores son uniformes, ahora introducimos los conceptos de _queries_ y _keys_ para ver como computar los ponderadores a partir de los datos. ALINEAR EXPLICACION CON DIAGRAMA DE RASCHKA.\n","\n","* Un _query_ $q(\\cdot)$ corresponde a una proyecci√≥n lineal de la representaci√≥n de _embeddings_ de un token particular. Por ejemplo, se proyecto $\\mathbb{R}^{C}\\rightarrow \\mathbb{R}^{H}$.\n","* Los _keys_ es la matriz $K\\in\\mathbb{R}^{T\\times H}$ que contiene proyecciones lineales de todos los _embeddings_ de tokens dentro del contexto, inclu√≠do el token que es el query. La proyecci√≥n lineal de los _keys_ es de igual tama√±o (i.e. $H$) que la proyecci√≥n del _query_.\n","* Los ponderadores para cada _query_ se obtiene a partir de qu√© tan pr√≥ximo se relaciona un token respecto al resto de los token dentro de un contexto. Por ejemplo, $q(x_i) \\times K$"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"a4f9611bdc5f426b87b42952cdf55d51","deepnote_cell_type":"code"},"outputs":[],"source":["from IPython.display import Image\n","Image(\"https://sebastianraschka.com/images/blog/2023/self-attention-from-scratch/attention-scores.png\")"]},{"cell_type":"markdown","metadata":{"cell_id":"991844ec775b4ce89cbaddb41e181f78","deepnote_cell_type":"image","deepnote_img_src":"image-20230904-194635.png"},"source":["<img src=\"image-20230904-194635.png\" width=\"\" align=\"\" />"]},{"cell_type":"markdown","metadata":{"cell_id":"2bdc17d026094321b7b1b6b53fd3bec9","deepnote_cell_type":"markdown"},"source":["> b) (Bonus): Explique porqu√© no se utilizan directamente los _embeddings_ para computar la matriz de atenci√≥n previo a la normalizaci√≥n, i.e. `(T,B).dot((B,T))`, en vez de usar las proyecciones $QK^\\top$."]},{"cell_type":"markdown","metadata":{"cell_id":"8bdb8dd7d9954b87b248303181315e57","deepnote_cell_type":"markdown"},"source":["> c) (Bonus): Explique los argumentos detras de escalar por $1/\\sqrt{d_k}$ referidos en el paper _[Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)_ (Vaswani 2017)."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"0a0761b6973342598468b3f265e85223","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":16,"execution_start":1693864851430,"source_hash":null},"outputs":[{"data":{"text/plain":["torch.Size([4, 8, 16])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# colocar seed como su RUT\n","torch.manual_seed(1337)\n","\n","B,T,C = 4,8,32  # batch, time, channels\n","x = torch.randn(B,T,C)"]},{"cell_type":"markdown","metadata":{"cell_id":"ff534d33b5ae46b5a252eaa2023dfa39","deepnote_cell_type":"markdown"},"source":["Ejemplo de aplicaci√≥n de m√≥dulo de atenci√≥n"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"64725c524c18451a843b2f837bd65dcd","deepnote_cell_type":"code"},"outputs":[],"source":["head_size = 16\n","key = nn.Linear(C, head_size, bias=False)\n","query = nn.Linear(C, head_size, bias=False)\n","value = nn.Linear(C, head_size, bias=False)\n","k = key(x)  # (B, T, 16)\n","q = query(x)  # (B, T, 16)\n","wei =  q @ k.transpose(-2, -1)  # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n","\n","tril = torch.tril(torch.ones(T, T))\n","# wei = torch.zeros((T,T))\n","wei = wei.masked_fill(tril == 0, float('-inf'))\n","wei = F.softmax(wei, dim=-1)\n","\n","v = value(x)\n","out = wei @ v\n","# out = wei @ x\n","\n","out.shape"]},{"cell_type":"markdown","metadata":{"cell_id":"5db2feb142554dddb5ce05738c1f743e","deepnote_cell_type":"markdown"},"source":["Observaciones:\n","- Atenci√≥n es un **mecanismo de comunicaci√≥n**. Puede ser entendido como nodos en un grafo dirigido conect√°ndose unos con otros y agregando informaci√≥n con una suma ponderada de todos los nodos que apuntan a ellos, con pesos dependientes de los datos.\n","- No hay una noci√≥n de espacio. Atenci√≥n simplemente actua sobre el conjunto de vectores. Es por este motivo que se necesitan encoders posicionales.\n","- Cada punto dentro de un batch es, desde luego, procesado de manera independiente y nunca intractua con los otros.\n","- En un bloque de atenci√≥n \"encoder\" basta comentar la linea que hace masking con `tril`, que hace que los tokens se comuniquen todos con todos. El bloque anterior se llama \"decoder\" porque aplica un masking triangular y se encuentre frecuentemente en configuraciones autoregresivas.\n","- \"auto-atenci√≥n\" (_self-attention_) s√≥lo signfica que tanto _keys_ como _values_ son producidas desde la misma fuente que las _queries_. En \"atenci√≥n-cruzada\" (_cross-attention_), las _queries_ vienen de $x$, pero _keys_ y _values_ vienen de otra fuente externa (como puede ser un modulo encoder).\n","- Atenci√≥n \"escalada\" divide `wei` por $\\frac{1}{\\sqrt{head\\_size}}$. Esto hace que cuando los input $Q$ y $K$ tengan varianza unitaria, `wei` tambi√©n tendr√° varianza unitaria y evitar√° la saturaci√≥n de la Softmax."]},{"cell_type":"markdown","metadata":{"cell_id":"833c93c83a6f42e6a9c6e3adce82a4be","deepnote_cell_type":"markdown"},"source":["> d) (1.5 ptos.) Cree una clase `Head`que implemente un m√≥dulo de auto-atenci√≥n."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"e86d22f778c4464894ee70eeb6f47ae1","deepnote_cell_type":"code"},"outputs":[],"source":["class Head(nn.Module):\n","    \"\"\" Una cabeza de auto-atenci√≥n \"\"\"\n","\n","    def __init__(self, head_size):\n","        super().__init__()\n","        # ------------------------\n","        self.key = None  # CAMBIAR\n","\n","        # etc ...\n","\n","        # ------------------------\n","        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        # input size (batch, time-step, channels)\n","        # output size (batch, time-step, head size)\n","        B,T,C = x.shape\n","        k = pass   # (B,T,hs)\n","        q = pass   # (B,T,hs)\n","        # --------------------------------------\n","\n","        # Computar los score de atenci√≥n (\"affinities\")\n","\n","        # --------------------------------------\n","        wei = pass # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n","        wei = pass # (B, T, T)\n","        wei = pass # (B, T, T)\n","        wei = self.dropout(wei)\n","        # --------------------------------------\n","\n","        # Adici√≥n (con pesos) de las atenciones\n","\n","        # --------------------------------------\n","\n","        v = self.value(x)  # (B,T,hs)\n","        out = wei @ v  # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n","        \n","        return out"]},{"cell_type":"markdown","metadata":{"cell_id":"96c2b9cefd6b453cb437392b7f03f5d4","deepnote_cell_type":"markdown"},"source":["La arquitectura decoder del paper Transformer implementa varias versiones de _self-attention_ en paralelo, cada una es una \"c√°beza de atenci√≥n\", y estas concatenan sus resultados en un modulo conocido como `MultiHeadAttention`."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"214c8ece545f4817b8561dfae0db408a","deepnote_cell_type":"code"},"outputs":[],"source":["class MultiHeadAttention(nn.Module):\n","    \"\"\" M√∫ltiples cabezas de auto-atenci√≥n en paralelo \"\"\"\n","\n","    def __init__(self, num_heads, head_size):\n","        super().__init__()\n","        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n","        self.proj = nn.Linear(head_size * num_heads, n_embd)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        out = torch.cat([h(x) for h in self.heads], dim=-1)\n","        out = self.dropout(self.proj(out))\n","        return out"]},{"cell_type":"markdown","metadata":{"cell_id":"5d5e70b87ba948e6b2db556e91caeac7","deepnote_cell_type":"markdown"},"source":["> e) (1 pto.) Implemente una clase `FeedForward` como se describe en el art√≠culo [\"Attention is all you need, Vaswani et al.\"](https://arxiv.org/pdf/1706.03762.pdf)."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"2bd2438a5180464c873da561e6a8527c","deepnote_cell_type":"code"},"outputs":[],"source":["class FeedFoward(nn.Module):\n","    \"\"\" \n","        Implementar FeedForward descrita en secci√≥n:\n","         \"3.3 Position-wise Feed-Fordward Networks\", paper\n","         \"Attention is All You Need\"\n","        https://arxiv.org/pdf/1706.03762.pdf\n","        \n","        in: n_embd\n","        out: n_embd\n","    \"\"\"\n","\n","    def __init__(self, n_embd):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            #nn.Linear(n_embd, 4 * n_embd),\n","            #nn.ReLU(),\n","            #nn.Linear(4 * n_embd, n_embd),\n","            nn.Dropout(dropout),\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"fd893f1e2d6842b08beb90dd1091e678","deepnote_cell_type":"code"},"outputs":[],"source":["Image(\"http://jalammar.github.io/images/gpt2/gpt2-transformer-block-vectors-2.png\")"]},{"cell_type":"markdown","metadata":{"cell_id":"06f8ac7c9ab1489f970271b5bae442ba","deepnote_cell_type":"image","deepnote_img_src":"image-20230904-203151.png"},"source":["<img src=\"image-20230904-203151.png\" width=\"\" align=\"\" />"]},{"cell_type":"markdown","metadata":{"cell_id":"e0384b1c93274e7abfb20d5627b2958c","deepnote_cell_type":"markdown"},"source":["> f) (0.5 ptos.) Explique la relaci√≥n entre los hiperpar√°metros `n_head` y `head_size` de la clase `MultiHeadAttention`. Piense en su rol dentro del bloque decoder (i.e. atenci√≥n + feedforward)."]},{"cell_type":"markdown","metadata":{"cell_id":"708d555c66ac4f4a940e82ab2251cb76","deepnote_cell_type":"markdown"},"source":["> g) (0.5 ptos.) Complete el paso _forward_ de la clase `EncoderBlock`. Recuerde en particula incorporar las conexiones residuales (_skip connections_)."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"8a013f2aceba4d7eb70390a12f21c308","deepnote_cell_type":"code"},"outputs":[],"source":["class EncoderBlock(nn.Module):\n","    \"\"\"  BloqueTransformer: COMUNICACI√ìN seguida de C√ìMPUTO \"\"\"\n","\n","    def __init__(self, n_embd, n_head):\n","        # n_embd: dimensi√≥n de embeddings, n_head: n√∫mero de cabezas de atenci√≥n\n","        super().__init__()\n","        head_size = n_embd // n_head\n","        self.sa = MultiHeadAttention(n_head, head_size)\n","        self.ffwd = FeedFoward(n_embd)\n","        self.ln1 = nn.LayerNorm(n_embd)\n","        self.ln2 = nn.LayerNorm(n_embd)\n","\n","    def forward(self, x):\n","        # ---------------------\n","\n","        x = pass  # completar\n","\n","        # ----------------------\n","\n","        return x"]},{"cell_type":"markdown","metadata":{"cell_id":"cd75ed98e96247ffa253556488b53e4e","deepnote_cell_type":"markdown"},"source":["## 5. Modelo GPT: Juntando todo"]},{"cell_type":"markdown","metadata":{"cell_id":"00e10b6c07f5442b95e5c2b0819edc0a","deepnote_cell_type":"markdown"},"source":["> h) (1 pto.) Complete el c√≥digo de la clase `GPTLanguageModel`procesando adecuadamente el input del modelo. Complete adem√°s el m√©todo `generate` para samplear elementos que completen auto-regresivamente una secuencia."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"88ed14ab007b4feea097aaa558f1cb73","deepnote_cell_type":"code"},"outputs":[],"source":["class GPTLanguageModel(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","        # cada token lee directamente los logits para el token siguiente de una lookup table\n","        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n","        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n","        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n","        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n","        self.lm_head = nn.Linear(n_embd, vocab_size)\n","\n","        self.apply(self._init_weights)\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","            if module.bias is not None:\n","                torch.nn.init.zeros_(module.bias)\n","        elif isinstance(module, nn.Embedding):\n","            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","\n","    def forward(self, idx, targets=None):\n","        B, T = idx.shape\n","\n","        # idx y targets son ambos tensores (B,T) de enteros\n","        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n","        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n","\n","        # -----------------------------\n","\n","        x = pass  # DEFINIR x, con shape (B,T,C)\n","\n","        # procesar x...\n","\n","        logits = pass  # CALCULAR logits (B,T,vocab_size)\n","\n","        # -------------------------------\n","\n","        if targets is None:\n","            loss = None\n","        else:\n","            B, T, C = logits.shape\n","            logits = logits.view(B*T, C)\n","            targets = targets.view(B*T)\n","            loss = F.cross_entropy(logits, targets)\n","\n","        return logits, loss\n","\n","    def generate(self, idx, max_new_tokens):\n","        # idx es un arreglo (B, T) de √≠ndices en el contexto actual\n","        for _ in range(max_new_tokens):\n","            # restringir idx a los √∫ltimos block_size tokens\n","            idx_cond = idx[:, -block_size:]\n","            # obtener las predicciones\n","            logits, loss = self(idx_cond)\n","            # enfocarse s√≥lo en el √∫ltimo paso\n","            logits = logits[:, -1, :]  # se convierte en size (B, C)\n","            # ------------------------------------------------------------\n","\n","            # aplicar softmax para obtener las probabilidades\n","            probs = pass  # tensor de dimensionalidad (B, C)\n","\n","            # definir una distribuci√≥n apropiada para samplear usando las probabilidades\n","            idx_next = pass  # tensor de √≠ndices de dim (B, 1)\n","\n","            # adjuntar el token generado a la secuencia (actualizando idx)\n","            idx = pass  # tensor resultante de dimensionalidad (B, T+1)\n","            \n","            # ------------------------------------------------------------\n","\n","        return idx\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"56fa2d0e8f424060841dfb5a0793b8e8","deepnote_cell_type":"code"},"outputs":[],"source":["model = GPTLanguageModel()\n","m = model.to(device)\n","# printear el n√∫mero de par√°metros del modelo\n","print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n","\n","# definir el optimizador de PyTorch\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"]},{"cell_type":"markdown","metadata":{"cell_id":"6cd551bb57f54567a9780b868c2081e7","deepnote_cell_type":"markdown"},"source":["> g) (1 pto.) Complete el bucle de entrenamiento usando comandos de `pytorch.optimize` conocidos. Ejecute el entrenamiento (se recomienda dejarlo corriendo e ir hacer algo m√°s...). Corrobore que se modelo es capaz de generar texto."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"faa0a3b9283247f1a8cf6d6b8d599959","deepnote_cell_type":"code"},"outputs":[],"source":["# hiper-par√°metros\n","batch_size = 64\n","block_size = 256  # largo de ventana m√°ximo para considerar en la precisi√≥n\n","\n","max_iters = 5000\n","eval_interval = 500\n","\n","learning_rate = 3e-4\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","eval_iters = 200\n","n_embd = 384\n","n_head = 6\n","n_layer = 6\n","dropout = 0.2\n","\n","# colocar RUT como semilla\n","torch.manual_seed(1337)\n","\n","for iter in range(max_iters):\n","\n","    # de vez en cuando evaluar la loss en los conjuntos de train y evaluaci√≥n\n","    if iter % eval_interval == 0 or iter == max_iters - 1:\n","        losses = estimate_loss()\n","        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n","\n","    # samplear un batch de datos\n","    xb, yb = get_batch('train')\n","\n","    # evaluate the loss\n","    logits, loss = model(xb, yb)\n","\n","    # ----------------------------------------\n","\n","    # activar el optimizador y hacer el paso backward con el resultado de la funci√≥n loss\n","\n","    # ----------------------------------------"]},{"cell_type":"markdown","metadata":{"cell_id":"5a8d031142ab45d48e9b9eeb81f6b2f7","deepnote_cell_type":"markdown"},"source":["## 6. Generando secuencias de texto con el modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"9e6d66e2a3ba49a4ae3c23d4e65d57df","deepnote_cell_type":"code"},"outputs":[],"source":["# Generar usando el modelo\n","context = torch.zeros((1, 1), dtype=torch.long, device=device)\n","print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))\n","\n","# Para escribir en un archivo\n","# open('output.txt', 'w').write(decode(m.generate(context, max_new_tokens=10000)[0].tolist()))"]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=42603f8c-d572-4f30-b66f-2f8f2cb33526' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"409cf1afb7654c8282dccc46f347e63f","deepnote_persisted_session":{"createdAt":"2023-09-04T22:31:43.624Z"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
